{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.077</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.082</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.084</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.9              0.22         0.48             1.8      0.077   \n",
       "1            7.6              0.39         0.31             2.3      0.082   \n",
       "2            7.9              0.43         0.21             1.6      0.106   \n",
       "3            8.5              0.49         0.11             2.3      0.084   \n",
       "4            6.9              0.40         0.14             2.4      0.085   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 29.0                  60.0   0.9968  3.39       0.53   \n",
       "1                 23.0                  71.0   0.9982  3.52       0.65   \n",
       "2                 10.0                  37.0   0.9966  3.17       0.91   \n",
       "3                  9.0                  67.0   0.9968  3.17       0.53   \n",
       "4                 21.0                  40.0   0.9968  3.43       0.63   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        6  \n",
       "1      9.7        5  \n",
       "2      9.5        5  \n",
       "3      9.4        5  \n",
       "4      9.7        6  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df=pd.read_csv(f'./data/TrainingDataset.csv', delimiter=';', quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_csv(f'./data/TrainingDataset.csv', delimiter=';')\n",
    "df_val = pd.read_csv(f'./data/ValidationDataset.csv', delimiter=';')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    66\n",
       "6    65\n",
       "7    22\n",
       "8     4\n",
       "4     2\n",
       "3     1\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "      <td>1279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.136669</td>\n",
       "      <td>0.530403</td>\n",
       "      <td>0.256536</td>\n",
       "      <td>2.505121</td>\n",
       "      <td>0.086533</td>\n",
       "      <td>16.082877</td>\n",
       "      <td>46.003127</td>\n",
       "      <td>0.996503</td>\n",
       "      <td>3.322338</td>\n",
       "      <td>0.650195</td>\n",
       "      <td>10.468139</td>\n",
       "      <td>5.641126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.626437</td>\n",
       "      <td>0.180198</td>\n",
       "      <td>0.192347</td>\n",
       "      <td>1.428187</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>10.548020</td>\n",
       "      <td>32.459117</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.148779</td>\n",
       "      <td>0.155140</td>\n",
       "      <td>1.059036</td>\n",
       "      <td>0.809894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995460</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.900000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997460</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.150000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.600000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1279.000000       1279.000000  1279.000000     1279.000000   \n",
       "mean        8.136669          0.530403     0.256536        2.505121   \n",
       "std         1.626437          0.180198     0.192347        1.428187   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.000000          0.390000     0.080000        1.900000   \n",
       "50%         7.800000          0.530000     0.240000        2.200000   \n",
       "75%         8.900000          0.640000     0.400000        2.500000   \n",
       "max        15.600000          1.580000     1.000000       15.400000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1279.000000          1279.000000           1279.000000  1279.000000   \n",
       "mean      0.086533            16.082877             46.003127     0.996503   \n",
       "std       0.047000            10.548020             32.459117     0.001815   \n",
       "min       0.034000             1.000000              6.000000     0.990070   \n",
       "25%       0.069000             8.000000             22.000000     0.995460   \n",
       "50%       0.078000            14.000000             38.000000     0.996400   \n",
       "75%       0.089000            22.000000             62.000000     0.997460   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1279.000000  1279.000000  1279.000000  1279.000000  \n",
       "mean      3.322338     0.650195    10.468139     5.641126  \n",
       "std       0.148779     0.155140     1.059036     0.809894  \n",
       "min       2.740000     0.330000     8.500000     3.000000  \n",
       "25%       3.220000     0.550000     9.500000     5.000000  \n",
       "50%       3.320000     0.620000    10.200000     6.000000  \n",
       "75%       3.410000     0.720000    11.150000     6.000000  \n",
       "max       4.010000     2.000000    14.000000     8.000000  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    529\n",
       "6    522\n",
       "7    161\n",
       "4     45\n",
       "8     13\n",
       "3      9\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.077</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.082</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.084</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.9              0.22         0.48             1.8      0.077   \n",
       "1            7.6              0.39         0.31             2.3      0.082   \n",
       "2            7.9              0.43         0.21             1.6      0.106   \n",
       "3            8.5              0.49         0.11             2.3      0.084   \n",
       "4            6.9              0.40         0.14             2.4      0.085   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 29.0                  60.0   0.9968  3.39       0.53   \n",
       "1                 23.0                  71.0   0.9982  3.52       0.65   \n",
       "2                 10.0                  37.0   0.9966  3.17       0.91   \n",
       "3                  9.0                  67.0   0.9968  3.17       0.53   \n",
       "4                 21.0                  40.0   0.9968  3.43       0.63   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        6  \n",
       "1      9.7        5  \n",
       "2      9.5        5  \n",
       "3      9.4        5  \n",
       "4      9.7        6  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "col = df_train.columns[:-1]\n",
    "df_train[col] = scaler.fit_transform(df_train[col])\n",
    "df_val[col] = scaler.fit_transform(df_val[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.390909</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.074523</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>0.190813</td>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>0.119760</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>0.309859</td>\n",
       "      <td>0.229682</td>\n",
       "      <td>0.596916</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.191617</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.212329</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>0.124783</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.109541</td>\n",
       "      <td>0.479442</td>\n",
       "      <td>0.338583</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.354545</td>\n",
       "      <td>0.253425</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.086655</td>\n",
       "      <td>0.112676</td>\n",
       "      <td>0.215548</td>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.338583</td>\n",
       "      <td>0.119760</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.209091</td>\n",
       "      <td>0.191781</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.088388</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.120141</td>\n",
       "      <td>0.494126</td>\n",
       "      <td>0.543307</td>\n",
       "      <td>0.179641</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.390909          0.068493         0.48        0.062069   0.074523   \n",
       "1       0.272727          0.184932         0.31        0.096552   0.083189   \n",
       "2       0.300000          0.212329         0.21        0.048276   0.124783   \n",
       "3       0.354545          0.253425         0.11        0.096552   0.086655   \n",
       "4       0.209091          0.191781         0.14        0.103448   0.088388   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.394366              0.190813  0.494126  0.511811   0.119760   \n",
       "1             0.309859              0.229682  0.596916  0.614173   0.191617   \n",
       "2             0.126761              0.109541  0.479442  0.338583   0.347305   \n",
       "3             0.112676              0.215548  0.494126  0.338583   0.119760   \n",
       "4             0.281690              0.120141  0.494126  0.543307   0.179641   \n",
       "\n",
       "    alcohol  quality  \n",
       "0  0.163636        6  \n",
       "1  0.218182        5  \n",
       "2  0.181818        5  \n",
       "3  0.163636        5  \n",
       "4  0.218182        6  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test=train_test_split(df_train.iloc[:,:-1],df_train.iloc[:,-1],test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           5       0.55      0.73      0.62        66\n",
      "           6       0.53      0.42      0.47        65\n",
      "           7       0.38      0.36      0.37        22\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.52       160\n",
      "   macro avg       0.74      0.25      0.24       160\n",
      "weighted avg       0.54      0.52      0.50       160\n",
      "\n",
      "------------------------------ \n",
      "\n",
      "model: KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.54      0.74      0.63        66\n",
      "           6       0.41      0.29      0.34        65\n",
      "           7       0.37      0.32      0.34        22\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.47       160\n",
      "   macro avg       0.55      0.23      0.22       160\n",
      "weighted avg       0.47      0.47      0.45       160\n",
      "\n",
      "------------------------------ \n",
      "\n",
      "model: SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           5       0.55      0.82      0.65        66\n",
      "           6       0.52      0.45      0.48        65\n",
      "           7       0.60      0.14      0.22        22\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.54       160\n",
      "   macro avg       0.78      0.23      0.23       160\n",
      "weighted avg       0.56      0.54      0.50       160\n",
      "\n",
      "------------------------------ \n",
      "\n",
      "model: LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       1.00      0.00      0.00         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           5       0.53      0.85      0.65        66\n",
      "           6       0.52      0.26      0.35        65\n",
      "           7       0.62      0.59      0.60        22\n",
      "           8       1.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.54       160\n",
      "   macro avg       0.78      0.28      0.27       160\n",
      "weighted avg       0.56      0.54      0.49       160\n",
      "\n",
      "------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [RandomForestClassifier(), KNeighborsClassifier(), SVC(), LogisticRegression()]\n",
    "scores = dict()\n",
    "\n",
    "for m in models:\n",
    "    m.fit(df_train.iloc[:,:-1],df_train.iloc[:,-1])\n",
    "    y_pred = m.predict(df_val.iloc[:,:-1])\n",
    "\n",
    "    print(f'model: {str(m)}')\n",
    "    print(classification_report(df_val.iloc[:,-1],y_pred, zero_division=1))\n",
    "    print('-'*30, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-30 18:34:34,598]\u001b[0m A new study created in memory with name: no-name-ba1b8a6a-f08e-4637-9c52-a7c13794f18f\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:36,111]\u001b[0m Trial 0 finished with value: 0.53125 and parameters: {'n_estimators': 714, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.53125.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:37,109]\u001b[0m Trial 1 finished with value: 0.5375 and parameters: {'n_estimators': 702, 'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:38,941]\u001b[0m Trial 2 finished with value: 0.53125 and parameters: {'n_estimators': 896, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 7, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:39,352]\u001b[0m Trial 3 finished with value: 0.53125 and parameters: {'n_estimators': 187, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:40,840]\u001b[0m Trial 4 finished with value: 0.5375 and parameters: {'n_estimators': 794, 'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:41,219]\u001b[0m Trial 5 finished with value: 0.525 and parameters: {'n_estimators': 170, 'criterion': 'entropy', 'max_depth': 23, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:43,260]\u001b[0m Trial 6 finished with value: 0.53125 and parameters: {'n_estimators': 703, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:44,010]\u001b[0m Trial 7 finished with value: 0.53125 and parameters: {'n_estimators': 432, 'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 5, 'min_samples_leaf': 6}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:45,607]\u001b[0m Trial 8 finished with value: 0.55 and parameters: {'n_estimators': 610, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:46,927]\u001b[0m Trial 9 finished with value: 0.54375 and parameters: {'n_estimators': 635, 'criterion': 'entropy', 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:47,630]\u001b[0m Trial 10 finished with value: 0.525 and parameters: {'n_estimators': 423, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:48,694]\u001b[0m Trial 11 finished with value: 0.53125 and parameters: {'n_estimators': 521, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 10}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:49,917]\u001b[0m Trial 12 finished with value: 0.53125 and parameters: {'n_estimators': 537, 'criterion': 'entropy', 'max_depth': 29, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:51,930]\u001b[0m Trial 13 finished with value: 0.54375 and parameters: {'n_estimators': 992, 'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 8}. Best is trial 8 with value: 0.55.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:52,582]\u001b[0m Trial 14 finished with value: 0.55625 and parameters: {'n_estimators': 304, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.55625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:53,223]\u001b[0m Trial 15 finished with value: 0.55625 and parameters: {'n_estimators': 308, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.55625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:53,838]\u001b[0m Trial 16 finished with value: 0.5625 and parameters: {'n_estimators': 315, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:53,867]\u001b[0m Trial 17 finished with value: 0.525 and parameters: {'n_estimators': 20, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:54,353]\u001b[0m Trial 18 finished with value: 0.54375 and parameters: {'n_estimators': 290, 'criterion': 'gini', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:54,408]\u001b[0m Trial 19 finished with value: 0.50625 and parameters: {'n_estimators': 26, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:55,184]\u001b[0m Trial 20 finished with value: 0.5375 and parameters: {'n_estimators': 334, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:55,715]\u001b[0m Trial 21 finished with value: 0.55 and parameters: {'n_estimators': 285, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:56,179]\u001b[0m Trial 22 finished with value: 0.55 and parameters: {'n_estimators': 211, 'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:56,834]\u001b[0m Trial 23 finished with value: 0.55625 and parameters: {'n_estimators': 399, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 16 with value: 0.5625.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:57,563]\u001b[0m Trial 24 finished with value: 0.56875 and parameters: {'n_estimators': 427, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 24 with value: 0.56875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:57,972]\u001b[0m Trial 25 finished with value: 0.5875 and parameters: {'n_estimators': 151, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:58,209]\u001b[0m Trial 26 finished with value: 0.55 and parameters: {'n_estimators': 116, 'criterion': 'gini', 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:58,329]\u001b[0m Trial 27 finished with value: 0.5375 and parameters: {'n_estimators': 79, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:34:59,492]\u001b[0m Trial 28 finished with value: 0.54375 and parameters: {'n_estimators': 457, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:00,336]\u001b[0m Trial 29 finished with value: 0.54375 and parameters: {'n_estimators': 374, 'criterion': 'entropy', 'max_depth': 18, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:00,686]\u001b[0m Trial 30 finished with value: 0.55 and parameters: {'n_estimators': 224, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:01,356]\u001b[0m Trial 31 finished with value: 0.55625 and parameters: {'n_estimators': 352, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:01,917]\u001b[0m Trial 32 finished with value: 0.525 and parameters: {'n_estimators': 256, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:02,482]\u001b[0m Trial 33 finished with value: 0.56875 and parameters: {'n_estimators': 388, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:03,009]\u001b[0m Trial 34 finished with value: 0.53125 and parameters: {'n_estimators': 478, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:03,166]\u001b[0m Trial 35 finished with value: 0.53125 and parameters: {'n_estimators': 123, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:04,366]\u001b[0m Trial 36 finished with value: 0.5375 and parameters: {'n_estimators': 565, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:04,733]\u001b[0m Trial 37 finished with value: 0.5625 and parameters: {'n_estimators': 189, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:04,922]\u001b[0m Trial 38 finished with value: 0.55625 and parameters: {'n_estimators': 145, 'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:05,531]\u001b[0m Trial 39 finished with value: 0.55625 and parameters: {'n_estimators': 238, 'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:07,360]\u001b[0m Trial 40 finished with value: 0.5625 and parameters: {'n_estimators': 754, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:09,416]\u001b[0m Trial 41 finished with value: 0.55 and parameters: {'n_estimators': 878, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:11,292]\u001b[0m Trial 42 finished with value: 0.5375 and parameters: {'n_estimators': 756, 'criterion': 'entropy', 'max_depth': 13, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:13,059]\u001b[0m Trial 43 finished with value: 0.54375 and parameters: {'n_estimators': 678, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:14,865]\u001b[0m Trial 44 finished with value: 0.5375 and parameters: {'n_estimators': 812, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 8, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:16,028]\u001b[0m Trial 45 finished with value: 0.54375 and parameters: {'n_estimators': 631, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:16,216]\u001b[0m Trial 46 finished with value: 0.5375 and parameters: {'n_estimators': 73, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:16,884]\u001b[0m Trial 47 finished with value: 0.525 and parameters: {'n_estimators': 406, 'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 7}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:17,132]\u001b[0m Trial 48 finished with value: 0.5375 and parameters: {'n_estimators': 183, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:18,291]\u001b[0m Trial 49 finished with value: 0.54375 and parameters: {'n_estimators': 576, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:19,418]\u001b[0m Trial 50 finished with value: 0.54375 and parameters: {'n_estimators': 489, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:20,151]\u001b[0m Trial 51 finished with value: 0.55625 and parameters: {'n_estimators': 450, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:20,798]\u001b[0m Trial 52 finished with value: 0.55 and parameters: {'n_estimators': 266, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:21,531]\u001b[0m Trial 53 finished with value: 0.54375 and parameters: {'n_estimators': 360, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:22,616]\u001b[0m Trial 54 finished with value: 0.53125 and parameters: {'n_estimators': 967, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:23,209]\u001b[0m Trial 55 finished with value: 0.575 and parameters: {'n_estimators': 324, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:23,577]\u001b[0m Trial 56 finished with value: 0.525 and parameters: {'n_estimators': 164, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:24,428]\u001b[0m Trial 57 finished with value: 0.56875 and parameters: {'n_estimators': 526, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:25,129]\u001b[0m Trial 58 finished with value: 0.55625 and parameters: {'n_estimators': 524, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:25,874]\u001b[0m Trial 59 finished with value: 0.5625 and parameters: {'n_estimators': 404, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:26,401]\u001b[0m Trial 60 finished with value: 0.5625 and parameters: {'n_estimators': 423, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:26,798]\u001b[0m Trial 61 finished with value: 0.55 and parameters: {'n_estimators': 315, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 10}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:27,378]\u001b[0m Trial 62 finished with value: 0.5625 and parameters: {'n_estimators': 394, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:28,075]\u001b[0m Trial 63 finished with value: 0.575 and parameters: {'n_estimators': 455, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:28,829]\u001b[0m Trial 64 finished with value: 0.5625 and parameters: {'n_estimators': 509, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:29,948]\u001b[0m Trial 65 finished with value: 0.54375 and parameters: {'n_estimators': 566, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:30,323]\u001b[0m Trial 66 finished with value: 0.55625 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:31,066]\u001b[0m Trial 67 finished with value: 0.575 and parameters: {'n_estimators': 501, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:31,806]\u001b[0m Trial 68 finished with value: 0.55625 and parameters: {'n_estimators': 460, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:32,406]\u001b[0m Trial 69 finished with value: 0.53125 and parameters: {'n_estimators': 595, 'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 9}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:33,487]\u001b[0m Trial 70 finished with value: 0.55 and parameters: {'n_estimators': 549, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:34,156]\u001b[0m Trial 71 finished with value: 0.58125 and parameters: {'n_estimators': 380, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:34,590]\u001b[0m Trial 72 finished with value: 0.5625 and parameters: {'n_estimators': 340, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 5, 'min_samples_leaf': 9}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:35,287]\u001b[0m Trial 73 finished with value: 0.56875 and parameters: {'n_estimators': 487, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:35,998]\u001b[0m Trial 74 finished with value: 0.575 and parameters: {'n_estimators': 494, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:37,041]\u001b[0m Trial 75 finished with value: 0.5375 and parameters: {'n_estimators': 468, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:37,545]\u001b[0m Trial 76 finished with value: 0.525 and parameters: {'n_estimators': 437, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:38,080]\u001b[0m Trial 77 finished with value: 0.5625 and parameters: {'n_estimators': 373, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 6}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:39,079]\u001b[0m Trial 78 finished with value: 0.5375 and parameters: {'n_estimators': 498, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:39,973]\u001b[0m Trial 79 finished with value: 0.58125 and parameters: {'n_estimators': 529, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:40,768]\u001b[0m Trial 80 finished with value: 0.55625 and parameters: {'n_estimators': 609, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:41,466]\u001b[0m Trial 81 finished with value: 0.56875 and parameters: {'n_estimators': 424, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:42,331]\u001b[0m Trial 82 finished with value: 0.56875 and parameters: {'n_estimators': 532, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:43,555]\u001b[0m Trial 83 finished with value: 0.56875 and parameters: {'n_estimators': 646, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:44,350]\u001b[0m Trial 84 finished with value: 0.5625 and parameters: {'n_estimators': 546, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:45,071]\u001b[0m Trial 85 finished with value: 0.55625 and parameters: {'n_estimators': 325, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:45,745]\u001b[0m Trial 86 finished with value: 0.55625 and parameters: {'n_estimators': 497, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:46,367]\u001b[0m Trial 87 finished with value: 0.54375 and parameters: {'n_estimators': 386, 'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:46,682]\u001b[0m Trial 88 finished with value: 0.51875 and parameters: {'n_estimators': 282, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:47,345]\u001b[0m Trial 89 finished with value: 0.56875 and parameters: {'n_estimators': 474, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 9}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:48,182]\u001b[0m Trial 90 finished with value: 0.5375 and parameters: {'n_estimators': 453, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:49,332]\u001b[0m Trial 91 finished with value: 0.55625 and parameters: {'n_estimators': 709, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:50,473]\u001b[0m Trial 92 finished with value: 0.575 and parameters: {'n_estimators': 635, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:51,304]\u001b[0m Trial 93 finished with value: 0.5625 and parameters: {'n_estimators': 581, 'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:52,758]\u001b[0m Trial 94 finished with value: 0.54375 and parameters: {'n_estimators': 644, 'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:53,502]\u001b[0m Trial 95 finished with value: 0.55 and parameters: {'n_estimators': 414, 'criterion': 'entropy', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:54,629]\u001b[0m Trial 96 finished with value: 0.54375 and parameters: {'n_estimators': 521, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:55,568]\u001b[0m Trial 97 finished with value: 0.55625 and parameters: {'n_estimators': 552, 'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:56,402]\u001b[0m Trial 98 finished with value: 0.56875 and parameters: {'n_estimators': 432, 'criterion': 'entropy', 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 25 with value: 0.5875.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:35:56,859]\u001b[0m Trial 99 finished with value: 0.55625 and parameters: {'n_estimators': 357, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 25 with value: 0.5875.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.5875\n",
      "  Params: \n",
      "    n_estimators: 151\n",
      "    criterion: entropy\n",
      "    max_depth: 11\n",
      "    min_samples_split: 4\n",
      "    min_samples_leaf: 2\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    train_x, train_y = df_train.iloc[:,:-1],df_train.iloc[:,-1]\n",
    "    valid_x, valid_y = df_val.iloc[:,:-1],df_val.iloc[:,-1]\n",
    "\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", ['gini', 'entropy']),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 2, 10)\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**param)\n",
    "\n",
    "    rf.fit(train_x, train_y)\n",
    "\n",
    "    preds = rf.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.5875,\n",
      "params {'n_estimators': 151, 'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_criterion</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>params_min_samples_split</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>2022-11-30 18:34:34.600418</td>\n",
       "      <td>2022-11-30 18:34:36.110120</td>\n",
       "      <td>0 days 00:00:01.509702</td>\n",
       "      <td>entropy</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>714</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.53750</td>\n",
       "      <td>2022-11-30 18:34:36.112124</td>\n",
       "      <td>2022-11-30 18:34:37.109614</td>\n",
       "      <td>0 days 00:00:00.997490</td>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>702</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>2022-11-30 18:34:37.110646</td>\n",
       "      <td>2022-11-30 18:34:38.941217</td>\n",
       "      <td>0 days 00:00:01.830571</td>\n",
       "      <td>entropy</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>896</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>2022-11-30 18:34:38.942222</td>\n",
       "      <td>2022-11-30 18:34:39.352553</td>\n",
       "      <td>0 days 00:00:00.410331</td>\n",
       "      <td>entropy</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>187</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.53750</td>\n",
       "      <td>2022-11-30 18:34:39.353557</td>\n",
       "      <td>2022-11-30 18:34:40.840249</td>\n",
       "      <td>0 days 00:00:01.486692</td>\n",
       "      <td>gini</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>794</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number    value             datetime_start          datetime_complete  \\\n",
       "0       0  0.53125 2022-11-30 18:34:34.600418 2022-11-30 18:34:36.110120   \n",
       "1       1  0.53750 2022-11-30 18:34:36.112124 2022-11-30 18:34:37.109614   \n",
       "2       2  0.53125 2022-11-30 18:34:37.110646 2022-11-30 18:34:38.941217   \n",
       "3       3  0.53125 2022-11-30 18:34:38.942222 2022-11-30 18:34:39.352553   \n",
       "4       4  0.53750 2022-11-30 18:34:39.353557 2022-11-30 18:34:40.840249   \n",
       "\n",
       "                duration params_criterion  params_max_depth  \\\n",
       "0 0 days 00:00:01.509702          entropy                23   \n",
       "1 0 days 00:00:00.997490             gini                 3   \n",
       "2 0 days 00:00:01.830571          entropy                19   \n",
       "3 0 days 00:00:00.410331          entropy                25   \n",
       "4 0 days 00:00:01.486692             gini                16   \n",
       "\n",
       "   params_min_samples_leaf  params_min_samples_split  params_n_estimators  \\\n",
       "0                        7                         7                  714   \n",
       "1                        5                         4                  702   \n",
       "2                        9                         7                  896   \n",
       "3                        7                        10                  187   \n",
       "4                        3                         9                  794   \n",
       "\n",
       "      state  \n",
       "0  COMPLETE  \n",
       "1  COMPLETE  \n",
       "2  COMPLETE  \n",
       "3  COMPLETE  \n",
       "4  COMPLETE  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optuna import visualization\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))\n",
    "hist = study.trials_dataframe()\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54375"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = df_train.iloc[:,:-1],df_train.iloc[:,-1]\n",
    "valid_x, valid_y = df_val.iloc[:,:-1],df_val.iloc[:,-1]\n",
    "\n",
    "param = {'n_estimators': 706, 'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 5, 'min_samples_leaf': 9}\n",
    "\n",
    "rf = RandomForestClassifier(**param)\n",
    "\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "preds = rf.predict(valid_x)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = accuracy_score(valid_y, pred_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-30 18:36:12,711]\u001b[0m A new study created in memory with name: no-name-5f8f7b50-8015-4bf3-b5f3-03e1ba2514ba\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:12,774]\u001b[0m Trial 0 finished with value: 0.5125 and parameters: {'kernel': 'sigmoid', 'degree': 5, 'gamma': 'auto'}. Best is trial 0 with value: 0.5125.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:12,840]\u001b[0m Trial 1 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:12,890]\u001b[0m Trial 2 finished with value: 0.5125 and parameters: {'kernel': 'sigmoid', 'degree': 4, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,373]\u001b[0m Trial 3 finished with value: 0.41875 and parameters: {'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,407]\u001b[0m Trial 4 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 4, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,452]\u001b[0m Trial 5 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 5, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,514]\u001b[0m Trial 6 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 5, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,588]\u001b[0m Trial 7 finished with value: 0.375 and parameters: {'kernel': 'sigmoid', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,663]\u001b[0m Trial 8 finished with value: 0.375 and parameters: {'kernel': 'sigmoid', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,714]\u001b[0m Trial 9 finished with value: 0.5125 and parameters: {'kernel': 'sigmoid', 'degree': 3, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,778]\u001b[0m Trial 10 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,839]\u001b[0m Trial 11 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,903]\u001b[0m Trial 12 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:13,970]\u001b[0m Trial 13 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,032]\u001b[0m Trial 14 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,069]\u001b[0m Trial 15 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 4, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,132]\u001b[0m Trial 16 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,196]\u001b[0m Trial 17 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,262]\u001b[0m Trial 18 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,302]\u001b[0m Trial 19 finished with value: 0.49375 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,338]\u001b[0m Trial 20 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 3, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,403]\u001b[0m Trial 21 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,466]\u001b[0m Trial 22 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,528]\u001b[0m Trial 23 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,590]\u001b[0m Trial 24 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,655]\u001b[0m Trial 25 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,717]\u001b[0m Trial 26 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,777]\u001b[0m Trial 27 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,817]\u001b[0m Trial 28 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,851]\u001b[0m Trial 29 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 3, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,913]\u001b[0m Trial 30 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:14,974]\u001b[0m Trial 31 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,036]\u001b[0m Trial 32 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,107]\u001b[0m Trial 33 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,170]\u001b[0m Trial 34 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,233]\u001b[0m Trial 35 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 1 with value: 0.5375.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,284]\u001b[0m Trial 36 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,738]\u001b[0m Trial 37 finished with value: 0.41875 and parameters: {'kernel': 'poly', 'degree': 5, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,778]\u001b[0m Trial 38 finished with value: 0.49375 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,817]\u001b[0m Trial 39 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,867]\u001b[0m Trial 40 finished with value: 0.5125 and parameters: {'kernel': 'sigmoid', 'degree': 2, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,907]\u001b[0m Trial 41 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 4, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:15,946]\u001b[0m Trial 42 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,027]\u001b[0m Trial 43 finished with value: 0.375 and parameters: {'kernel': 'sigmoid', 'degree': 4, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,092]\u001b[0m Trial 44 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 5, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,128]\u001b[0m Trial 45 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,189]\u001b[0m Trial 46 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 5, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,253]\u001b[0m Trial 47 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,330]\u001b[0m Trial 48 finished with value: 0.375 and parameters: {'kernel': 'sigmoid', 'degree': 5, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,393]\u001b[0m Trial 49 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,432]\u001b[0m Trial 50 finished with value: 0.4125 and parameters: {'kernel': 'poly', 'degree': 3, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,499]\u001b[0m Trial 51 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,563]\u001b[0m Trial 52 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,629]\u001b[0m Trial 53 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,692]\u001b[0m Trial 54 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,755]\u001b[0m Trial 55 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 3, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,818]\u001b[0m Trial 56 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 4, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,852]\u001b[0m Trial 57 finished with value: 0.5125 and parameters: {'kernel': 'linear', 'degree': 5, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,916]\u001b[0m Trial 58 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:16,979]\u001b[0m Trial 59 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,041]\u001b[0m Trial 60 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'auto'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,104]\u001b[0m Trial 61 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,166]\u001b[0m Trial 62 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,228]\u001b[0m Trial 63 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,290]\u001b[0m Trial 64 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,352]\u001b[0m Trial 65 finished with value: 0.5375 and parameters: {'kernel': 'rbf', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,403]\u001b[0m Trial 66 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,452]\u001b[0m Trial 67 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,503]\u001b[0m Trial 68 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,554]\u001b[0m Trial 69 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,606]\u001b[0m Trial 70 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,667]\u001b[0m Trial 71 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,724]\u001b[0m Trial 72 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,774]\u001b[0m Trial 73 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,825]\u001b[0m Trial 74 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,875]\u001b[0m Trial 75 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,927]\u001b[0m Trial 76 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:17,978]\u001b[0m Trial 77 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,029]\u001b[0m Trial 78 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,080]\u001b[0m Trial 79 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,131]\u001b[0m Trial 80 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,182]\u001b[0m Trial 81 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,234]\u001b[0m Trial 82 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,284]\u001b[0m Trial 83 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,336]\u001b[0m Trial 84 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,389]\u001b[0m Trial 85 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,439]\u001b[0m Trial 86 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,490]\u001b[0m Trial 87 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,541]\u001b[0m Trial 88 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,595]\u001b[0m Trial 89 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,660]\u001b[0m Trial 90 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,711]\u001b[0m Trial 91 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,761]\u001b[0m Trial 92 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,813]\u001b[0m Trial 93 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,868]\u001b[0m Trial 94 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,921]\u001b[0m Trial 95 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:18,976]\u001b[0m Trial 96 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:19,031]\u001b[0m Trial 97 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:19,084]\u001b[0m Trial 98 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n",
      "\u001b[32m[I 2022-11-30 18:36:19,136]\u001b[0m Trial 99 finished with value: 0.575 and parameters: {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}. Best is trial 36 with value: 0.575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.575\n",
      "  Params: \n",
      "    kernel: poly\n",
      "    degree: 2\n",
      "    gamma: scale\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    train_x, train_y = df_train.iloc[:,:-1],df_train.iloc[:,-1]\n",
    "    valid_x, valid_y = df_val.iloc[:,:-1],df_val.iloc[:,-1]\n",
    "\n",
    "    param = {\n",
    "        \"kernel\": trial.suggest_categorical(\"kernel\", ['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "        \"degree\": trial.suggest_int(\"degree\", 2, 5),\n",
    "        \"gamma\": trial.suggest_categorical(\"gamma\", ['scale', 'auto']),\n",
    "    }\n",
    "\n",
    "    svc = SVC(**param)\n",
    "\n",
    "    svc.fit(train_x, train_y)\n",
    "\n",
    "    preds = svc.predict(valid_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(valid_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.575,\n",
      "params {'kernel': 'poly', 'degree': 2, 'gamma': 'scale'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_degree</th>\n",
       "      <th>params_gamma</th>\n",
       "      <th>params_kernel</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>2022-11-30 18:36:12.713057</td>\n",
       "      <td>2022-11-30 18:36:12.773817</td>\n",
       "      <td>0 days 00:00:00.060760</td>\n",
       "      <td>5</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.53750</td>\n",
       "      <td>2022-11-30 18:36:12.776138</td>\n",
       "      <td>2022-11-30 18:36:12.840459</td>\n",
       "      <td>0 days 00:00:00.064321</td>\n",
       "      <td>2</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>2022-11-30 18:36:12.841905</td>\n",
       "      <td>2022-11-30 18:36:12.889416</td>\n",
       "      <td>0 days 00:00:00.047511</td>\n",
       "      <td>4</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.41875</td>\n",
       "      <td>2022-11-30 18:36:12.891428</td>\n",
       "      <td>2022-11-30 18:36:13.373268</td>\n",
       "      <td>0 days 00:00:00.481840</td>\n",
       "      <td>5</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.51250</td>\n",
       "      <td>2022-11-30 18:36:13.374266</td>\n",
       "      <td>2022-11-30 18:36:13.407770</td>\n",
       "      <td>0 days 00:00:00.033504</td>\n",
       "      <td>4</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number    value             datetime_start          datetime_complete  \\\n",
       "0       0  0.51250 2022-11-30 18:36:12.713057 2022-11-30 18:36:12.773817   \n",
       "1       1  0.53750 2022-11-30 18:36:12.776138 2022-11-30 18:36:12.840459   \n",
       "2       2  0.51250 2022-11-30 18:36:12.841905 2022-11-30 18:36:12.889416   \n",
       "3       3  0.41875 2022-11-30 18:36:12.891428 2022-11-30 18:36:13.373268   \n",
       "4       4  0.51250 2022-11-30 18:36:13.374266 2022-11-30 18:36:13.407770   \n",
       "\n",
       "                duration  params_degree params_gamma params_kernel     state  \n",
       "0 0 days 00:00:00.060760              5         auto       sigmoid  COMPLETE  \n",
       "1 0 days 00:00:00.064321              2         auto           rbf  COMPLETE  \n",
       "2 0 days 00:00:00.047511              4         auto       sigmoid  COMPLETE  \n",
       "3 0 days 00:00:00.481840              5        scale          poly  COMPLETE  \n",
       "4 0 days 00:00:00.033504              4        scale        linear  COMPLETE  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optuna import visualization\n",
    "print('Best trial: score {},\\nparams {}'.format(study.best_trial.value,study.best_trial.params))\n",
    "hist = study.trials_dataframe()\n",
    "hist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, train_y = df_train.iloc[:,:-1],df_train.iloc[:,-1]\n",
    "valid_x, valid_y = df_val.iloc[:,:-1],df_val.iloc[:,-1]\n",
    "\n",
    "param = {'kernel': 'linear', 'degree': 3, 'gamma': 'auto'}\n",
    "\n",
    "svc = SVC(**param)\n",
    "\n",
    "svc.fit(train_x, train_y)\n",
    "\n",
    "preds = svc.predict(valid_x)\n",
    "pred_labels = np.rint(preds)\n",
    "accuracy = accuracy_score(valid_y, pred_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Data type string of column fixed acidity is not supported.\nData type string of column volatile acidity is not supported.\nData type string of column citric acid is not supported.\nData type string of column residual sugar is not supported.\nData type string of column chlorides is not supported.\nData type string of column free sulfur dioxide is not supported.\nData type string of column total sulfur dioxide is not supported.\nData type string of column density is not supported.\nData type string of column pH is not supported.\nData type string of column sulphates is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\r0rschach\\Desktop\\Cloud Computing\\Projects\\WineQualityPrediction\\wine.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m spark_model \u001b[39m=\u001b[39m SparkTorch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     inputCol\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     labelCol\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_c0\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# # Can be used in a pipeline and saved.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m p \u001b[39m=\u001b[39m Pipeline(stages\u001b[39m=\u001b[39;49m[vector_assembler, spark_model])\u001b[39m.\u001b[39;49mfit(df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/r0rschach/Desktop/Cloud%20Computing/Projects/WineQualityPrediction/wine.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m p\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39msimple_dnn\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\pyspark\\ml\\base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_fit(dataset)\n\u001b[0;32m    204\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(dataset)\n\u001b[0;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params)\n\u001b[0;32m    210\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\pyspark\\ml\\pipeline.py:132\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(stage, Transformer):\n\u001b[0;32m    131\u001b[0m     transformers\u001b[39m.\u001b[39mappend(stage)\n\u001b[1;32m--> 132\u001b[0m     dataset \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39;49mtransform(dataset)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# must be an Estimator\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     model \u001b[39m=\u001b[39m stage\u001b[39m.\u001b[39mfit(dataset)\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(params)\u001b[39m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(dataset)\n\u001b[0;32m    263\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mParams must be a param map but got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mtype\u001b[39m(params))\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\pyspark\\ml\\wrapper.py:400\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_java_obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 400\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrame(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_java_obj\u001b[39m.\u001b[39;49mtransform(dataset\u001b[39m.\u001b[39;49m_jdf), dataset\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\py4j\\java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[1;32mc:\\Users\\r0rschach\\anaconda3\\envs\\yo1\\lib\\site-packages\\pyspark\\sql\\utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: Data type string of column fixed acidity is not supported.\nData type string of column volatile acidity is not supported.\nData type string of column citric acid is not supported.\nData type string of column residual sugar is not supported.\nData type string of column chlorides is not supported.\nData type string of column free sulfur dioxide is not supported.\nData type string of column total sulfur dioxide is not supported.\nData type string of column density is not supported.\nData type string of column pH is not supported.\nData type string of column sulphates is not supported."
     ]
    }
   ],
   "source": [
    "# using sparktorch - getting errors\n",
    "\n",
    "\n",
    "# from sparktorch import serialize_torch_obj, SparkTorch\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from pyspark.ml.feature import VectorAssembler\n",
    "# from pyspark.sql import SparkSession\n",
    "# from pyspark.ml.pipeline import Pipeline\n",
    "\n",
    "# spark = SparkSession.builder.appName(\"examples\").getOrCreate()\n",
    "# df = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv(f'./data/TrainingDataset.csv')\n",
    "\n",
    "# network = nn.Sequential(\n",
    "#     nn.Linear(11, 10),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Softmax(dim=1)\n",
    "# )\n",
    "\n",
    "# # Build the pytorch object\n",
    "# torch_obj = serialize_torch_obj(\n",
    "#     model=network,\n",
    "#     criterion=nn.CrossEntropyLoss(),\n",
    "#     optimizer=torch.optim.Adam,\n",
    "#     lr=0.0001\n",
    "# )\n",
    "\n",
    "# # Setup features\n",
    "# vector_assembler = VectorAssembler(inputCols=df.columns[:10], outputCol='quality')\n",
    "\n",
    "# # Create a SparkTorch Model with torch distributed. Barrier execution is on by default for this mode.\n",
    "# spark_model = SparkTorch(\n",
    "#     inputCol='features',\n",
    "#     labelCol='_c0',\n",
    "#     predictionCol='predictions',\n",
    "#     torchObj=torch_obj,\n",
    "#     iters=50,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # # Can be used in a pipeline and saved.\n",
    "# p = Pipeline(stages=[vector_assembler, spark_model]).fit(df)\n",
    "# p.save('simple_dnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.077</td>\n",
       "      <td>29.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.082</td>\n",
       "      <td>23.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.084</td>\n",
       "      <td>9.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            8.9              0.22         0.48             1.8      0.077   \n",
       "1            7.6              0.39         0.31             2.3      0.082   \n",
       "2            7.9              0.43         0.21             1.6      0.106   \n",
       "3            8.5              0.49         0.11             2.3      0.084   \n",
       "4            6.9              0.40         0.14             2.4      0.085   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 29.0                  60.0   0.9968  3.39       0.53   \n",
       "1                 23.0                  71.0   0.9982  3.52       0.65   \n",
       "2                 10.0                  37.0   0.9966  3.17       0.91   \n",
       "3                  9.0                  67.0   0.9968  3.17       0.53   \n",
       "4                 21.0                  40.0   0.9968  3.43       0.63   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        6  \n",
       "1      9.7        5  \n",
       "2      9.5        5  \n",
       "3      9.4        5  \n",
       "4      9.7        6  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'./data/TrainingDataset.csv', delimiter=';')\n",
    "df_val = pd.read_csv(f'./data/ValidationDataset.csv', delimiter=';')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5\n",
      "0     0.0  0.0  0.0  1.0  0.0  0.0\n",
      "1     0.0  0.0  1.0  0.0  0.0  0.0\n",
      "2     0.0  0.0  1.0  0.0  0.0  0.0\n",
      "3     0.0  0.0  1.0  0.0  0.0  0.0\n",
      "4     0.0  0.0  0.0  1.0  0.0  0.0\n",
      "...   ...  ...  ...  ...  ...  ...\n",
      "1274  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "1275  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "1276  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "1277  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "1278  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "\n",
      "[1279 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer \n",
    " \n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on 'team' column \n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(df_train[['quality']]).toarray())\n",
    "\n",
    "#merge one-hot encoded columns back with original DataFrame\n",
    "# final_df = df.join(encoder_df)\n",
    "\n",
    "#view final df\n",
    "print(encoder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.iloc[:,:-1].to_numpy()\n",
    "y_train = encoder_df.to_numpy()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4  ,  0.7  ,  0.   , ...,  3.51 ,  0.56 ,  9.4  ],\n",
       "       [ 7.8  ,  0.88 ,  0.   , ...,  3.2  ,  0.68 ,  9.8  ],\n",
       "       [ 7.8  ,  0.76 ,  0.04 , ...,  3.26 ,  0.65 ,  9.8  ],\n",
       "       ...,\n",
       "       [15.6  ,  0.645,  0.49 , ...,  2.92 ,  0.74 , 11.1  ],\n",
       "       [10.9  ,  0.53 ,  0.49 , ...,  3.07 ,  0.56 , 11.7  ],\n",
       "       [13.   ,  0.47 ,  0.49 , ...,  3.3  ,  0.68 , 12.7  ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = df_val.iloc[:,:-1].to_numpy()\n",
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5\n",
      "0    0.0  0.0  1.0  0.0  0.0  0.0\n",
      "1    0.0  0.0  1.0  0.0  0.0  0.0\n",
      "2    0.0  0.0  1.0  0.0  0.0  0.0\n",
      "3    0.0  0.0  0.0  1.0  0.0  0.0\n",
      "4    0.0  0.0  1.0  0.0  0.0  0.0\n",
      "..   ...  ...  ...  ...  ...  ...\n",
      "155  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "156  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "157  0.0  0.0  1.0  0.0  0.0  0.0\n",
      "158  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "159  0.0  0.0  0.0  1.0  0.0  0.0\n",
      "\n",
      "[160 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on 'team' column \n",
    "y_val = pd.DataFrame(encoder.fit_transform(df_val[['quality']]).toarray())\n",
    "\n",
    "#merge one-hot encoded columns back with original DataFrame\n",
    "# final_df = df.join(encoder_df)\n",
    "\n",
    "#view final df\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 60        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 36        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96\n",
      "Trainable params: 96\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(5, activation ='relu', input_shape =(11, )))\n",
    "\n",
    "# model.add(Dense(10, activation ='relu'))\n",
    "\n",
    "model.add(Dense(6, activation ='sigmoid'))\n",
    " \n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss ='binary_crossentropy',\n",
    "  optimizer ='adam', metrics =['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1279/1279 [==============================] - 2s 1ms/step - loss: 0.5620 - accuracy: 0.4152\n",
      "Epoch 2/3\n",
      "1279/1279 [==============================] - 1s 944us/step - loss: 0.4206 - accuracy: 0.3901\n",
      "Epoch 3/3\n",
      "1279/1279 [==============================] - 1s 899us/step - loss: 0.3695 - accuracy: 0.3972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2000487c250>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 3,\n",
    "           batch_size = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1000us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365],\n",
       "       [0.07647708, 0.10413905, 0.42416722, 0.42303383, 0.18323573,\n",
       "        0.08008365]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('yo1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a444e92c75e3c639596f55d125a4fa617444de481e075ca5864d60af4c89cbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
